#.\concatenar.py

import os

# extensões que você quer juntar
EXTENSOES = {".html", ".py", ".js", ".css"}

# pastas que você quer ignorar
IGNORAR_PASTAS = {"venv", "__pycache__",'node_modules'}

# pasta base
PASTA_BASE = "."

# arquivo final
ARQUIVO_SAIDA = "arquivos_concatenados.txt"


def concatenar_arquivos(pasta_base, arquivo_saida):
    with open(arquivo_saida, "w", encoding="utf-8") as saida:
        for root, dirs, files in os.walk(pasta_base):
            # remove pastas que não devem ser exploradas
            dirs[:] = [
                d for d in dirs
                if d not in IGNORAR_PASTAS and not d.startswith(".")
            ]

            for file in files:
                _, ext = os.path.splitext(file)
                if ext.lower() in EXTENSOES:
                    caminho = os.path.join(root, file)

                    # escreve cabeçalho com caminho
                    saida.write(f"#{caminho}\n\n")

                    try:
                        with open(caminho, "r", encoding="utf-8", errors="ignore") as f:
                            conteudo = f.read()
                            saida.write(conteudo.strip())
                    except Exception as e:
                        saida.write(f"## Erro ao ler {caminho}: {e}")

                    # separador
                    saida.write("\n\n--------\n\n")


if __name__ == "__main__":
    concatenar_arquivos(PASTA_BASE, ARQUIVO_SAIDA)
    print(f"Concatenação concluída! Arquivo salvo em: {ARQUIVO_SAIDA}")

--------

#.\construir_banco_de_cenas.py

import os
import sqlite3
import json
from tqdm import tqdm

# ==============================================================================
# --- CONFIGURAÇÃO ---
# ==============================================================================

# 1. Pasta raiz onde estão as subpastas das categorias (atrizes/estúdios)
#    (Ex: 'backend/videos')
VIDEOS_ROOT_FOLDER = "backend/videos"

# 2. Nome e caminho do arquivo do banco de dados que será criado/atualizado
DB_FILE = "cenas_database.db"

# 3. Duração mínima (em segundos) que uma cena deve ter para ser catalogada
MIN_SCENE_DURATION = 2.0

# ==============================================================================
# --- FUNÇÕES AUXILIARES ---
# ==============================================================================

def setup_database(db_path):
    """
    Cria a estrutura de tabelas no banco de dados SQLite.
    Se o arquivo já existir, ele será usado; não será apagado.
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("PRAGMA foreign_keys = ON;")

    cursor.execute("""
    CREATE TABLE IF NOT EXISTS videos (
        video_id INTEGER PRIMARY KEY,
        video_name TEXT NOT NULL UNIQUE,
        category TEXT,
        file_path TEXT
    )""")
    
    # [MODIFICADO] A coluna clip_path agora pode ser NULL
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS scenes (
        scene_id INTEGER PRIMARY KEY,
        video_id INTEGER NOT NULL,
        scene_number INTEGER NOT NULL,
        start_time REAL NOT NULL,
        end_time REAL NOT NULL,
        duration REAL NOT NULL,
        clip_path TEXT, -- Será preenchido sob demanda
        FOREIGN KEY (video_id) REFERENCES videos(video_id) ON DELETE CASCADE
    )""")
    
    cursor.execute("CREATE TABLE IF NOT EXISTS tags (tag_id INTEGER PRIMARY KEY, tag_name TEXT NOT NULL UNIQUE)")
    
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS scene_tags (
        scene_id INTEGER NOT NULL,
        tag_id INTEGER NOT NULL,
        score REAL NOT NULL,
        PRIMARY KEY (scene_id, tag_id),
        FOREIGN KEY (scene_id) REFERENCES scenes(scene_id) ON DELETE CASCADE,
        FOREIGN KEY (tag_id) REFERENCES tags(tag_id)
    )""")
    
    conn.commit()
    print(f"Banco de dados '{db_path}' conectado e estrutura verificada.")
    return conn

# ==============================================================================
# --- FUNÇÃO PRINCIPAL ---
# ==============================================================================
def build_scene_database():
    """
    Função principal que varre as pastas, processa os JSONs e popula o
    banco de dados com informações de vídeos e cenas, SEM extrair os clipes.
    """
    conn = setup_database(DB_FILE)
    cursor = conn.cursor()

    try:
        category_folders = [d for d in os.listdir(VIDEOS_ROOT_FOLDER) if os.path.isdir(os.path.join(VIDEOS_ROOT_FOLDER, d)) and not d.startswith('.')]
    except FileNotFoundError:
        print(f"ERRO: A pasta raiz de vídeos '{VIDEOS_ROOT_FOLDER}' não foi encontrada.")
        return

    for category_name in tqdm(category_folders, desc="Processando Categorias"):
        category_folder_path = os.path.join(VIDEOS_ROOT_FOLDER, category_name)
        
        json_files = [f for f in os.listdir(category_folder_path) if f.endswith("_cenas.json")]

        for json_filename in tqdm(json_files, desc=f"  Vídeos de '{category_name}'", leave=False):
            base_video_name = json_filename.replace("_cenas.json", "")
            
            source_video_path = None
            for ext in ['.mp4', '.mkv', '.mov', '.webm', '.avi', '.wmv', '.mpg']:
                path_try = os.path.join(category_folder_path, f"{base_video_name}{ext}")
                if os.path.exists(path_try):
                    source_video_path = path_try
                    break
            
            if not source_video_path:
                tqdm.write(f"Aviso: Vídeo original para '{json_filename}' não encontrado. Pulando.")
                continue

            cursor.execute("INSERT OR IGNORE INTO videos (video_name, category, file_path) VALUES (?, ?, ?)", 
                           (base_video_name, category_name, source_video_path.replace(os.path.sep, '/')))
            cursor.execute("SELECT video_id FROM videos WHERE video_name = ?", (base_video_name,))
            video_id = cursor.fetchone()[0]
            
            json_path = os.path.join(category_folder_path, json_filename)
            with open(json_path, 'r', encoding='utf-8') as f:
                try: scenes_data = json.load(f)
                except json.JSONDecodeError: continue

            if not isinstance(scenes_data, list): continue

            for scene in scenes_data:
                scene_duration = scene.get('duration', 0)
                if scene_duration < MIN_SCENE_DURATION:
                    continue
                
                # Insere a cena no DB sem o clip_path
                cursor.execute("INSERT INTO scenes (video_id, scene_number, start_time, end_time, duration) VALUES (?, ?, ?, ?, ?)",
                               (video_id, scene.get('cena_n'), scene.get('start_time'), scene.get('end_time'), scene_duration))
                scene_id = cursor.lastrowid

                # Insere as tags e as relações
                for tag_name, score in scene.get('tags_principais', {}).items():
                    tag_name_std = tag_name.replace(' ', '_')
                    cursor.execute("INSERT OR IGNORE INTO tags (tag_name) VALUES (?)", (tag_name_std,))
                    cursor.execute("SELECT tag_id FROM tags WHERE tag_name = ?", (tag_name_std,))
                    tag_id = cursor.fetchone()[0]
                    cursor.execute("INSERT OR IGNORE INTO scene_tags (scene_id, tag_id, score) VALUES (?, ?, ?)",
                                   (scene_id, tag_id, score))

            # Salva as alterações no DB para este vídeo
            conn.commit()
    
    conn.close()
    print("\n--- Processo de catalogação do banco de dados concluído! ---")
    print("Nenhum clipe de vídeo foi extraído, apenas as informações foram salvas.")

# ==============================================================================
# --- EXECUÇÃO ---
# ==============================================================================
if __name__ == "__main__":
    build_scene_database()

--------

#.\converter.py

import os
import subprocess
from tqdm import tqdm

# ==============================================================================
# --- CONFIGURAÇÃO ---
# ==============================================================================

# A pasta raiz que contém as subpastas de cada atriz com os vídeos.
VIDEO_ROOT_FOLDER = os.path.join("web", "videos")

# Formatos a serem convertidos. Adicione outros se necessário.
FORMATS_TO_CONVERT = ('.wmv', '.avi', '.mkv', '.mpg', '.mpeg', '.flv', '.mov')

# ==============================================================================
# --- FUNÇÃO PRINCIPAL DE CONVERSÃO ---
# ==============================================================================

def convert_videos_to_mp4():
    """
    Varre as pastas de vídeo, converte formatos antigos para MP4 usando a GPU,
    e deleta os arquivos originais.
    """
    print(f"--- Iniciando a conversão de vídeos em '{VIDEO_ROOT_FOLDER}' para MP4 ---")

    videos_to_convert = []
    # Encontra todos os arquivos que precisam de conversão
    for root, _, files in os.walk(VIDEO_ROOT_FOLDER):
        for file in files:
            if file.lower().endswith(FORMATS_TO_CONVERT):
                videos_to_convert.append(os.path.join(root, file))

    if not videos_to_convert:
        print("Nenhum vídeo para converter. Todos já estão em formato moderno ou a pasta está vazia.")
        return

    print(f"Encontrados {len(videos_to_convert)} vídeos para converter.")

    success_count = 0
    fail_count = 0

    for video_path in tqdm(videos_to_convert, desc="Convertendo vídeos"):
        base_path, _ = os.path.splitext(video_path)
        output_path = f"{base_path}.mp4"
        
        # Comando de conversão com aceleração por GPU (NVENC)
        # '-c:v h264_nvenc' -> Encoder de vídeo da Nvidia
        # '-preset fast' -> Bom equilíbrio de velocidade/qualidade
        # '-c:a aac' -> Codec de áudio padrão e compatível
        command = [
            'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
            '-i', video_path,
            '-c:v', 'h264_nvenc',
            '-preset', 'fast',
            '-c:a', 'aac',
            '-b:a', '192k',
            output_path
        ]

        try:
            # Executa a conversão
            subprocess.run(command, check=True)
            
            # Se a conversão foi bem-sucedida, deleta o original
            os.remove(video_path)
            
            # [CRUCIAL] Renomeia o arquivo JSON correspondente, se existir
            original_json_path = f"{base_path}_cenas.json"
            new_json_path = f"{base_path}.mp4_cenas.json" # Temporário
            final_json_path = f"{base_path}_cenas.json" # O nome final correto

            if os.path.exists(original_json_path):
                # Renomeia para um nome temporário para evitar conflitos se o .mp4 já existia
                os.rename(original_json_path, new_json_path)
                # Renomeia de volta para o nome final, agora que o original se foi
                os.rename(new_json_path, final_json_path)

            success_count += 1
        except subprocess.CalledProcessError:
            tqdm.write(f"  ERRO: Falha ao converter '{os.path.basename(video_path)}'. Pode ser um codec não suportado pela GPU.")
            # Opcional: Adicionar um fallback para CPU aqui se quiser ser exaustivo
            fail_count += 1
        except Exception as e:
            tqdm.write(f"  ERRO inesperado com '{os.path.basename(video_path)}': {e}")
            fail_count += 1
            
    print("\n--- Conversão Concluída ---")
    print(f"✅ Convertidos com sucesso: {success_count}")
    print(f"❌ Falhas: {fail_count}")

if __name__ == "__main__":
    convert_videos_to_mp4()

--------

#.\backend\app\main.py

import os
from pathlib import Path
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from app.api import videos
from app.api import search

# --- [NOVO] INICIALIZAÇÃO E CRIAÇÃO DE DIRETÓRIOS ---
# Define o caminho base da pasta 'backend'
BASE_DIR = Path(__file__).resolve().parent.parent

# Define os caminhos para as pastas que a aplicação precisa
VIDEOS_DIR = BASE_DIR / "videos"
CLIPS_DIR = BASE_DIR / "clips"

# Garante que as pastas essenciais existam ao iniciar a aplicação
os.makedirs(VIDEOS_DIR, exist_ok=True)
os.makedirs(CLIPS_DIR, exist_ok=True)
# --- FIM DA NOVA SEÇÃO ---

app = FastAPI(title="Video Scene Detector API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Monta a pasta de clipes como um diretório estático
# Agora a pasta 'clips' já foi criada, então este comando não falhará
app.mount("/clips", StaticFiles(directory=CLIPS_DIR), name="clips")

# Inclui os roteadores da API
app.include_router(videos.router, prefix="/api", tags=["Media & Processing"])
app.include_router(search.router, prefix="/api", tags=["Search"])

@app.get("/")
def read_root():
    return {"message": "Backend is running!"}

--------

#.\backend\app\api\search.py

import sqlite3
from fastapi import APIRouter, Depends, HTTPException
from app.core.schemas import SearchRequest
from pathlib import Path
import json

router = APIRouter()

BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent
DB_FILE = BASE_DIR / "cenas_database.db"

def get_db():
    db = sqlite3.connect(DB_FILE)
    db.row_factory = sqlite3.Row
    try:
        yield db
    finally:
        db.close()

@router.post("/search_videos", tags=["Search"], summary="Busca vídeos que contêm cenas com critérios específicos")
def search_videos_with_matching_scenes(request: SearchRequest, db: sqlite3.Connection = Depends(get_db)):
    """
    Busca vídeos e retorna uma lista de vídeos que contêm pelo menos uma cena
    que corresponde aos critérios de busca. A resposta inclui os IDs das cenas correspondentes.
    """
    
    # --- Subquery para encontrar os scene_ids que correspondem aos critérios ---
    subquery_conditions = []
    subquery_params = []
    
    # Duração
    if request.min_duration is not None:
        subquery_conditions.append("s.duration >= ?")
        subquery_params.append(request.min_duration)
    if request.max_duration is not None:
        subquery_conditions.append("s.duration <= ?")
        subquery_params.append(request.max_duration)
        
    # Exclusão de tags
    if request.exclude_tags:
        for tag in request.exclude_tags:
            subquery_conditions.append(f"""
            s.scene_id NOT IN (
                SELECT st_exclude.scene_id FROM scene_tags st_exclude
                JOIN tags t_exclude ON st_exclude.tag_id = t_exclude.tag_id
                WHERE t_exclude.tag_name = ?
            )""")
            subquery_params.append(tag)
    
    # Construção da subquery
    subquery_where = " AND ".join(subquery_conditions) if subquery_conditions else "1=1"
    
    # Inclusão de tags (GROUP BY / HAVING)
    subquery_having = ""
    if request.include_tags:
        placeholders = ', '.join('?' for _ in request.include_tags)
        subquery_having = f"GROUP BY s.scene_id HAVING COUNT(DISTINCT t.tag_name) = ?"
        subquery_params.extend(request.include_tags)
        subquery_params.append(len(request.include_tags))

    # --- Query Principal para agrupar por vídeo ---
    query = f"""
    SELECT
        v.video_id,
        v.video_name,
        v.file_path,
        json_group_array(DISTINCT s_match.scene_id) as matching_scene_ids
    FROM videos v
    JOIN scenes s_match ON v.video_id = s_match.video_id
    WHERE s_match.scene_id IN (
        -- A subquery encontra as cenas correspondentes
        SELECT s.scene_id
        FROM scenes s
        JOIN scene_tags st ON s.scene_id = st.scene_id
        JOIN tags t ON st.tag_id = t.tag_id
        WHERE {subquery_where}
        {subquery_having}
    )
    GROUP BY v.video_id
    """
    
    # Paginação (opcional para vídeos, mas boa prática)
    # query += " LIMIT ? OFFSET ?"
    # params.extend([request.limit, (request.page - 1) * request.limit])

    try:
        cursor = db.cursor()
        print(f"Executando query: {query}")
        print(f"Com parâmetros: {subquery_params}")
        results = cursor.execute(query, subquery_params).fetchall()

        videos = []
        for row in results:
            video = dict(row)
            # Deserializa a string JSON dos IDs
            video['matching_scene_ids'] = json.loads(video['matching_scene_ids'])
            videos.append(video)
        
        return {"results": videos}
    except sqlite3.Error as e:
        raise HTTPException(status_code=500, detail=f"Erro no banco de dados: {e}")

--------

#.\backend\app\api\videos.py

import os
import shutil
import subprocess
import uuid
from pathlib import Path
import mimetypes
import json

from fastapi import (APIRouter, BackgroundTasks, HTTPException, WebSocket,
                     WebSocketDisconnect)
from fastapi.responses import FileResponse

from app.core.websockets import manager
# Supondo que seu serviço de processamento esteja pronto e importável
# Se o arquivo ainda não existe, crie um placeholder ou comente esta linha
from app.services.processing_service import run_scene_detection

# ==============================================================================
# --- CONFIGURAÇÃO DO ROTEADOR E CAMINHOS ---
# ==============================================================================
router = APIRouter()

# Usando pathlib para uma manipulação de caminhos mais robusta
BASE_DIR = Path(__file__).resolve().parent.parent.parent # Vai para a raiz da pasta /backend
VIDEOS_BASE_PATH = BASE_DIR / "videos"
THUMBNAIL_CACHE_PATH = VIDEOS_BASE_PATH / ".thumbnails" # Pasta oculta para cache

# Cria a pasta de cache de thumbnails na inicialização, se não existir
os.makedirs(THUMBNAIL_CACHE_PATH, exist_ok=True)


# ==============================================================================
# --- ENDPOINTS DE LISTAGEM ---
# ==============================================================================

@router.get("/folders", tags=["Folders"], summary="Lista todas as pastas de vídeo de primeiro nível")
def get_folders():
    """
    Escaneia o diretório base de vídeos e retorna uma lista de todas as subpastas.
    """
    try:
        all_items = os.listdir(VIDEOS_BASE_PATH)
        folders = [
            item for item in all_items
            if os.path.isdir(VIDEOS_BASE_PATH / item) and not item.startswith('.')
        ]
        return {"folders": sorted(folders)}
    except FileNotFoundError:
        raise HTTPException(
            status_code=404,
            detail=f"Diretório base de vídeos não encontrado em '{VIDEOS_BASE_PATH}'"
        )


@router.get("/videos/{folder_name}", tags=["Videos"], summary="Lista os vídeos em uma pasta específica")
def get_videos_in_folder(folder_name: str):
    """
    Lista os arquivos de vídeo em uma pasta específica e verifica o status de processamento.
    """
    folder_path = VIDEOS_BASE_PATH / folder_name
    if not os.path.isdir(folder_path):
        raise HTTPException(status_code=404, detail="Pasta não encontrada")

    supported_extensions = ('.mp4', '.mkv', '.mov', '.avi', '.webm', '.mpg', '.wmv')
    videos = []

    try:
        for filename in sorted(os.listdir(folder_path)):
            if filename.lower().endswith(supported_extensions):
                base_name, _ = os.path.splitext(filename)
                
                # O JSON de cenas é salvo na mesma pasta do vídeo por padrão
                json_path = folder_path / f"{base_name}_cenas.json"
                
                video_info = {
                    "filename": filename,
                    "folder": folder_name,
                    "has_scenes_json": os.path.exists(json_path),
                }
                videos.append(video_info)
        
        return {"videos": videos}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao ler a pasta: {e}")


# ==============================================================================
# --- ENDPOINTS DE MÍDIA (THUMBNAILS E STREAMING) ---
# ==============================================================================

@router.get("/thumbnail/{folder_name}/{filename}", tags=["Media"], summary="Gera e serve uma thumbnail")
def get_thumbnail(folder_name: str, filename: str):
    """
    Gera uma thumbnail para um vídeo (se não existir no cache) e a serve como um arquivo de imagem.
    """
    video_path = VIDEOS_BASE_PATH / folder_name / filename
    thumbnail_filename = f"{os.path.splitext(filename)[0]}.jpg"
    thumbnail_path = THUMBNAIL_CACHE_PATH / thumbnail_filename

    if not os.path.exists(video_path):
        raise HTTPException(status_code=404, detail="Vídeo não encontrado")

    if not os.path.exists(thumbnail_path):
        try:
            # Comando FFmpeg para extrair um frame de forma eficiente
            command = [
                'ffmpeg', '-ss', '5', '-i', str(video_path),
                '-vframes', '1', '-q:v', '3', '-vf', 'scale=320:-1',
                str(thumbnail_path)
            ]
            subprocess.run(command, check=True, capture_output=True, text=True)
        except subprocess.CalledProcessError as e:
            # Se falhar, talvez o vídeo tenha menos de 5s, tenta no início
            try:
                command = [
                    'ffmpeg', '-i', str(video_path),
                    '-vframes', '1', '-q:v', '3', '-vf', 'scale=320:-1',
                    str(thumbnail_path)
                ]
                subprocess.run(command, check=True, capture_output=True, text=True)
            except Exception:
                raise HTTPException(status_code=500, detail="Falha ao gerar thumbnail")

    return FileResponse(thumbnail_path)


@router.get("/stream/{folder_name}/{filename}", tags=["Media"], summary="Serve um arquivo de vídeo")
def stream_video(folder_name: str, filename: str):
    """
    Serve um arquivo de vídeo para ser reproduzido no player do frontend.
    Determina o tipo de mídia (MIME type) dinamicamente a partir da extensão do arquivo.
    """
    video_path = VIDEOS_BASE_PATH / folder_name / filename
    
    # Imprime no console do backend o caminho que ele está tentando acessar.
    # Isso é EXTREMAMENTE útil para depuração!
    print(f"Tentando servir o vídeo: {video_path}")

    if not os.path.exists(video_path):
        print(f"ERRO: Arquivo não encontrado em {video_path}")
        raise HTTPException(status_code=404, detail=f"Vídeo não encontrado em {video_path}")
    
    # Determina o tipo de mídia (MIME type) dinamicamente
    media_type, _ = mimetypes.guess_type(video_path)
    if media_type is None:
        # Se não conseguir adivinhar, usa um padrão genérico
        media_type = "application/octet-stream"

    return FileResponse(video_path, media_type=media_type, headers={"Accept-Ranges": "bytes"})

# ==============================================================================
# --- ENDPOINTS DE PROCESSAMENTO E WEBSOCKET ---
# ==============================================================================

@router.post("/process/{folder_name}/{filename}", status_code=202, tags=["Processing"], summary="Inicia a análise de cenas")
async def process_video(folder_name: str, filename: str, background_tasks: BackgroundTasks):
    """
    Inicia o processo de detecção de cena para um vídeo em segundo plano.
    Retorna imediatamente um 'job_id' para o cliente se conectar via WebSocket.
    """
    video_path = str(VIDEOS_BASE_PATH / folder_name / filename)
    output_folder = str(VIDEOS_BASE_PATH / folder_name)
    
    if not os.path.exists(video_path):
        raise HTTPException(status_code=404, detail="Vídeo não encontrado")

    job_id = str(uuid.uuid4())

    async def progress_callback(data: dict):
        await manager.send_json(job_id, data)

    background_tasks.add_task(
        run_scene_detection,
        video_path=video_path,
        output_folder=output_folder,
        callback=progress_callback
    )
    
    return {"job_id": job_id, "message": "Processamento iniciado"}


@router.websocket("/ws/progress/{job_id}")
async def websocket_endpoint(websocket: WebSocket, job_id: str):
    """
    Endpoint WebSocket que o cliente usa para receber atualizações de progresso
    para um 'job_id' específico.
    """
    await manager.connect(job_id, websocket)
    try:
        while True:
            # Mantém a conexão viva esperando por mensagens (não esperamos nenhuma do cliente)
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(job_id)

@router.get("/scenes/{folder_name}/{filename}", tags=["Scenes"], summary="Retorna os dados das cenas de um vídeo processado")
def get_scene_data(folder_name: str, filename: str):
    """
    Lê o arquivo _cenas.json e retorna seu conteúdo de forma segura,
    lidando com todos os tipos de erros de formatação ou conteúdo.
    """
    base_name, _ = os.path.splitext(filename)
    json_path = VIDEOS_BASE_PATH / folder_name / f"{base_name}_cenas.json"

    print(f"\n[DEBUG] Tentando buscar cenas para o arquivo: {json_path}")

    if not os.path.exists(json_path):
        print(f"[DEBUG] Arquivo de cenas não encontrado. Retornando vazio.")
        return {"scenes": [], "duration": 0}

    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # Se o arquivo estiver vazio, json.load() falha. Tratamos isso primeiro.
            if not content:
                print(f"[DEBUG] O arquivo JSON está vazio. Retornando vazio.")
                return {"scenes": [], "duration": 0}
            scene_data = json.loads(content)

    except json.JSONDecodeError:
        print(f"[DEBUG] ERRO: O arquivo JSON '{json_path}' está corrompido.")
        return {"scenes": [], "duration": 0}
    except Exception as e:
        print(f"[DEBUG] ERRO Inesperado ao ler o arquivo: {e}")
        raise HTTPException(status_code=500, detail=f"Erro inesperado ao ler o arquivo: {e}")

    # --- LÓGICA DE VALIDAÇÃO DO CONTEÚDO ---
    if not isinstance(scene_data, list):
        print(f"[DEBUG] Aviso: O conteúdo do JSON não é uma lista. É do tipo {type(scene_data)}.")
        return {"scenes": [], "duration": 0}
        
    if not scene_data:
        print("[DEBUG] A lista de cenas no JSON está vazia.")
        return {"scenes": [], "duration": 0}
        
    # Filtra apenas as cenas válidas (que são dicionários com as chaves necessárias)
    valid_scenes = []
    for scene in scene_data:
        if isinstance(scene, dict) and 'start_time' in scene and 'end_time' in scene and 'duration' in scene:
            valid_scenes.append(scene)

    if not valid_scenes:
        print("[DEBUG] Nenhuma cena válida encontrada dentro da lista no JSON.")
        return {"scenes": [], "duration": 0}

    # Calcula a duração a partir da última cena válida
    total_duration = valid_scenes[-1]['end_time']
    
    print(f"[DEBUG] Sucesso! Encontradas {len(valid_scenes)} cenas válidas. Duração total: {total_duration}")
    return {"scenes": valid_scenes, "duration": total_duration}

--------

#.\backend\app\core\schemas.py

from pydantic import BaseModel
from typing import List, Optional

class SearchRequest(BaseModel):
    """
    Define a estrutura dos dados que esperamos receber do frontend
    para uma requisição de busca.
    """
    # Optional[] significa que o campo não é obrigatório
    include_tags: Optional[List[str]] = []
    exclude_tags: Optional[List[str]] = []
    min_duration: Optional[float] = None
    max_duration: Optional[float] = None
    sort_by: Optional[str] = 'score' # Padrão para ordenar por score da tag (relevância)
    page: int = 1
    limit: int = 24

--------

#.\backend\app\core\websockets.py

from fastapi import WebSocket

class ConnectionManager:
    def __init__(self):
        self.active_connections: dict[str, WebSocket] = {}

    async def connect(self, job_id: str, websocket: WebSocket):
        await websocket.accept()
        self.active_connections[job_id] = websocket

    def disconnect(self, job_id: str):
        if job_id in self.active_connections:
            del self.active_connections[job_id]

    async def send_json(self, job_id: str, data: dict):
        if job_id in self.active_connections:
            await self.active_connections[job_id].send_json(data)

manager = ConnectionManager()

--------

#.\backend\app\services\processing_service.py

import os
import subprocess
import shutil
import huggingface_hub
import numpy as np
import onnxruntime as rt
import pandas as pd
from PIL import Image
import json
import re
import torch
import asyncio

# ==============================================================================
# SEÇÃO 1: CONSTANTES E CONFIGURAÇÕES DO MODELO
# ==============================================================================
MODEL_REPO = "SmilingWolf/wd-swinv2-tagger-v3"
GENERAL_THRESHOLD = 0.35
CHARACTER_THRESHOLD = 0.85
BATCH_SIZE = 4 # Tamanho de lote padrão, pode ser sobrescrito

# ==============================================================================
# SEÇÃO 2: CLASSE E FUNÇÕES AUXILIARES DE MACHINE LEARNING
# ==============================================================================

# (Estas são as funções do seu script do Colab, praticamente inalteradas)
kaomojis = ["0_0", "(o)_(o)", "+_+", "+_-", "._.", "<o>_<o>", "<|>_<|>", "=_=", ">_<", "3_3", "6_9", ">_o", "@_@", "^_^", "o_o", "u_u", "x_x", "|_|", "||_||"]

def load_labels(dataframe):
    name_series = dataframe["name"].map(lambda x: x.replace("_", " ") if x not in kaomojis else x)
    return name_series.tolist(), list(np.where(dataframe["category"] == 9)[0]), list(np.where(dataframe["category"] == 0)[0]), list(np.where(dataframe["category"] == 4)[0])

class Predictor:
    def __init__(self):
        self.model = None
        self.tag_names = None
        self.rating_indexes = None
        self.general_indexes = None
        self.character_indexes = None
        self.model_target_size = None
        self.last_loaded_repo = None

    def load_model(self, model_repo=MODEL_REPO):
        if self.last_loaded_repo == model_repo: return
        
        csv_path = huggingface_hub.hf_hub_download(model_repo, "selected_tags.csv")
        model_path = huggingface_hub.hf_hub_download(model_repo, "model.onnx")
        
        self.tag_names, self.rating_indexes, self.general_indexes, self.character_indexes = load_labels(pd.read_csv(csv_path))
        providers = ['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']
        self.model = rt.InferenceSession(model_path, providers=providers)
        _, height, _, _ = self.model.get_inputs()[0].shape
        self.model_target_size = height
        self.last_loaded_repo = model_repo

    def prepare_image(self, image):
        image = image.convert("RGB")
        max_dim = max(image.size)
        padded_image = Image.new("RGB", (max_dim, max_dim), (255, 255, 255))
        padded_image.paste(image, ((max_dim - image.size[0]) // 2, (max_dim - image.size[1]) // 2))
        if max_dim != self.model_target_size:
            padded_image = padded_image.resize((self.model_target_size, self.model_target_size), Image.BICUBIC)
        image_array = np.asarray(padded_image, dtype=np.float32)[:, :, ::-1]
        return np.expand_dims(image_array, axis=0)

    def predict_batch(self, images, general_thresh, character_thresh):
        batch_array = np.vstack([self.prepare_image(img) for img in images])
        input_name = self.model.get_inputs()[0].name
        label_name = self.model.get_outputs()[0].name
        preds_batch = self.model.run([label_name], {input_name: batch_array})[0]
        batch_results = []
        for preds in preds_batch:
            labels = list(zip(self.tag_names, preds.astype(float)))
            general_names = [labels[i] for i in self.general_indexes]
            character_names = [labels[i] for i in self.character_indexes]
            general_res = {x[0]: float(x[1]) for x in general_names if x[1] > general_thresh}
            character_res = {x[0]: float(x[1]) for x in character_names if x[1] > character_thresh}
            batch_results.append({**general_res, **character_res})
        return batch_results

# ==============================================================================
# SEÇÃO 3: FUNÇÕES DO PIPELINE DE PROCESSAMENTO (ADAPTADAS COM CALLBACK)
# ==============================================================================

# [MODIFICADO] A função extrair_frames agora é síncrona
def extrair_frames(caminho_video, diretorio_saida, fps):
    os.makedirs(diretorio_saida, exist_ok=True)
    caminho_saida_frames = os.path.join(diretorio_saida, 'frame_%06d.png')
    comando = ['ffmpeg', '-i', caminho_video, '-vf', f'fps={fps}', '-hide_banner', '-loglevel', 'error', caminho_saida_frames]
    
    # Usando o subprocess.run síncrono e confiável
    result = subprocess.run(comando, capture_output=True, text=True)

    if result.returncode != 0:
        # Imprime o erro do ffmpeg para ajudar na depuração
        print("Erro no FFmpeg (extrair_frames):", result.stderr)
        raise Exception(f"Falha na extração de frames. FFmpeg stderr: {result.stderr}")
    
    return len([f for f in os.listdir(diretorio_saida) if f.endswith('.png')])


async def gerar_tags_para_frames(predictor, pasta_frames, total_frames, batch_size, callback):
    results = {}
    img_files = sorted([f for f in os.listdir(pasta_frames) if f.lower().endswith('.png')])

    for i in range(0, len(img_files), batch_size):
        batch_file_names = img_files[i:i + batch_size]
        batch_images = [Image.open(os.path.join(pasta_frames, f)) for f in batch_file_names]
        
        batch_tags = predictor.predict_batch(batch_images, GENERAL_THRESHOLD, CHARACTER_THRESHOLD)
        
        for file_name, tags in zip(batch_file_names, batch_tags):
            results[file_name] = tags
        
        progress_percent = int(((i + len(batch_file_names)) / total_frames) * 100)
        overall_progress = 10 + int(0.7 * progress_percent) 
        await callback({"status": "processing", "progress": overall_progress, "message": f"Tagging frames ({progress_percent}%)"})

    return results

def detectar_trocas_de_cena(dados_tags, fps, limiar_similaridade):
    def calcular_similaridade_jaccard(tags1, tags2):
        set1, set2 = set(tags1.keys()), set(tags2.keys())
        intersecao = set1.intersection(set2)
        uniao = set1.union(set2)
        return len(intersecao) / len(uniao) if uniao else 1.0

    frames_ordenados = sorted(dados_tags.keys(), key=lambda x: int(re.search(r'(\d+)', x).group(1)))
    trocas_de_cena = [0.0]
    for i in range(len(frames_ordenados) - 1):
        similaridade = calcular_similaridade_jaccard(dados_tags[frames_ordenados[i]], dados_tags[frames_ordenados[i+1]])
        if similaridade < limiar_similaridade:
            trocas_de_cena.append((i + 1) / fps)
    return trocas_de_cena, frames_ordenados

def agrupar_cenas_com_tags(trocas_de_cena, frames_ordenados, dados_tags, fps, video_duration):
    cenas_agrupadas = []
    trocas_de_cena.append(video_duration)
    for i in range(len(trocas_de_cena) - 1):
        start_time, end_time = trocas_de_cena[i], trocas_de_cena[i+1]
        start_frame_idx = int(start_time * fps)
        end_frame_idx = int(end_time * fps)
        frames_da_cena = frames_ordenados[start_frame_idx:end_frame_idx]
        tags_agregadas = {}
        for frame_nome in frames_da_cena:
            for tag, score in dados_tags.get(frame_nome, {}).items():
                tags_agregadas.setdefault(tag, []).append(score)
        tags_medias = {tag: np.mean(scores) for tag, scores in tags_agregadas.items()}
        tags_principais = sorted(tags_medias.items(), key=lambda item: item[1], reverse=True)
        cenas_agrupadas.append({
            "cena_n": i + 1, "start_time": round(start_time, 3), "end_time": round(end_time, 3),
            "duration": round(end_time - start_time, 3),
            "tags_principais": {tag: round(score, 3) for tag, score in tags_principais}
        })
    return cenas_agrupadas

# ==============================================================================
# SEÇÃO 4: FUNÇÃO ORQUESTRADORA PRINCIPAL
# ==============================================================================

# Instância única do predictor para evitar recarregar o modelo
predictor = Predictor()

async def run_scene_detection(video_path: str, output_folder: str, callback,
                              fps: float = 1.0, limiar_similaridade: float = 0.4, batch_size: int = BATCH_SIZE):
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    # Usa uma pasta temporária na raiz do backend
    temp_frames_path = os.path.join("temp_processing", f"temp_{base_name}_{os.getpid()}")
    os.makedirs(temp_frames_path, exist_ok=True)
    
    try:
        if predictor.model is None:
            await callback({"status": "processing", "progress": 0, "message": "Carregando modelo de IA..."})
            predictor.load_model()

        # 1. Extrair Frames (chamada síncrona)
        await callback({"status": "processing", "progress": 5, "message": f"Extraindo frames a {fps} FPS..."})
        num_frames = extrair_frames(video_path, temp_frames_path, fps) # Não precisa mais de await
        if num_frames == 0:
            raise Exception("Nenhum frame foi extraído do vídeo.")

        # 2. Gerar Tags (ainda async por causa do callback)
        await callback({"status": "processing", "progress": 10, "message": "Iniciando tagging de frames..."})
        dados_tags = await gerar_tags_para_frames(predictor, temp_frames_path, num_frames, batch_size, callback)
        if not dados_tags:
            raise Exception("Falha ao gerar tags para os frames.")

        # 3. Obter duração do vídeo (chamada síncrona)
        await callback({"status": "processing", "progress": 80, "message": "Analisando cenas..."})
        ffprobe_cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', video_path]
        result = subprocess.run(ffprobe_cmd, capture_output=True, text=True, check=True)
        video_duration = float(result.stdout.strip())

        # ... (Resto da lógica síncrona) ...
        trocas_de_cena, frames_ordenados = detectar_trocas_de_cena(dados_tags, fps, limiar_similaridade)
        cenas_agrupadas = agrupar_cenas_com_tags(trocas_de_cena, frames_ordenados, dados_tags, fps, video_duration)

        await callback({"status": "processing", "progress": 95, "message": "Salvando resultados..."})
        json_output_path = os.path.join(output_folder, f"{base_name}_cenas.json")
        with open(json_output_path, 'w', encoding='utf-8') as f:
            json.dump(cenas_agrupadas, f, indent=4, ensure_ascii=False)

        await callback({"status": "completed", "progress": 100, "message": "Processamento concluído!"})

    except Exception as e:
        await callback({"status": "error", "message": str(e)})
        raise e
    finally:
        if os.path.exists(temp_frames_path):
            shutil.rmtree(temp_frames_path)

--------

#.\frontend\eslint.config.js

import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'
import { defineConfig, globalIgnores } from 'eslint/config'

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{js,jsx}'],
    extends: [
      js.configs.recommended,
      reactHooks.configs['recommended-latest'],
      reactRefresh.configs.vite,
    ],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    rules: {
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
    },
  },
])

--------

#.\frontend\index.html

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>

--------

#.\frontend\vite.config.js

import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react-swc'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

--------

#.\frontend\src\App.css

body {
  background-color: #1a1a1a;
  color: white;
  font-family: sans-serif;
  margin: 0;
}

.App-header {
  background-color: #242424;
  padding: 1rem;
  text-align: center;
  border-bottom: 1px solid #444;
}

.main-content {
  display: flex;
}

.sidebar {
  width: 250px;
  padding: 1rem;
  border-right: 1px solid #444;
  height: calc(100vh - 75px); /* Altura total menos o header */
  overflow-y: auto;
}

.content {
  flex-grow: 1;
  padding: 1rem;
}

.folder-list ul {
  list-style-type: none;
  padding: 0;
}

.folder-list li {
  background-color: #333;
  margin-bottom: 0.5rem;
  padding: 0.75rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background-color 0.2s;
}

.folder-list li:hover {
  background-color: #4a4a4a;
}

.grid-placeholder {
  color: #888;
  font-style: italic;
}

/* Estilos para o VideoGrid e VideoCard */
.video-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(220px, 1fr));
  gap: 1rem;
}

.video-card {
  background-color: #242424;
  border-radius: 8px;
  overflow: hidden;
  border: 1px solid #444;
}

.video-thumbnail {
  background-color: #333;
  height: 120px;
  display: flex;
  align-items: center;
  justify-content: center;
  color: #888;
}

.video-info {
  padding: 0.75rem;
}

.video-title {
  font-weight: bold;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  margin: 0 0 0.5rem 0;
}

.video-status {
  font-size: 0.9em;
  color: #ccc;
  margin: 0;
}

.video-card button {
    width: 100%;
    padding: 8px;
    margin-top: 8px;
    background-color: #5f27cd;
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
}
.video-card button:disabled {
    background-color: #333;
    cursor: not-allowed;
}
.progress-bar {
    background-color: #444;
    padding: 8px;
    margin-top: 8px;
    border-radius: 4px;
    text-align: center;
    font-size: 0.9em;
}

.video-thumbnail img {
  width: 100%;
  height: 100%;
  object-fit: cover; /* Garante que a imagem cubra a área sem distorcer */
}

.video-card {
  /* Adicione isso para o cursor indicar que é clicável */
  cursor: pointer;
}

.App-header nav {
  margin-top: 1rem;
}

.App-header nav a {
  color: white;
  text-decoration: none;
  margin: 0 1rem;
  padding: 0.5rem;
  border-radius: 4px;
  transition: background-color 0.2s;
}

.App-header nav a:hover {
  background-color: #444;
}

--------

#.\frontend\src\index.css

:root {
  font-family: system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}

--------

#.\frontend\src\components\PlayerModal.css

.modal-overlay {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.75);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
}

.modal-content {
  background-color: #242424;
  padding: 20px;
  border-radius: 8px;
  position: relative;
  width: 80%;
  max-width: 900px;
}

.close-button {
  position: absolute;
  top: 10px;
  right: 10px;
  background: none;
  border: none;
  color: white;
  font-size: 1.5rem;
  cursor: pointer;
}

.player-wrapper {
  position: relative;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
}

.react-player {
  position: absolute;
  top: 0;
  left: 0;
}

--------

#.\frontend\src\components\SceneProgressBar.css

.progress-bar-container {
  width: 100%;
  height: 20px;
  background-color: #333;
  display: flex;
  position: relative;
  cursor: pointer;
  margin-top: 10px;
  border-radius: 4px;
  overflow: hidden;
}

.scene-segment {
  height: 100%;
  transition: filter 0.2s ease-in-out;
}

.scene-segment:hover {
  filter: brightness(1.3);
}

.playhead {
  position: absolute;
  top: 0;
  left: 0;
  width: 3px;
  height: 100%;
  background-color: white;
  transform: translateX(-50%); /* Centraliza o pino */
  pointer-events: none; /* Garante que o clique passe para a barra abaixo */
}

.scene-segment.dimmed {
  opacity: 0.4;
}

--------

#.\frontend\src\pages\SearchPage.css

.search-page {
  padding: 1rem;
}

.search-form {
  display: flex;
  gap: 1rem;
  margin-bottom: 2rem;
  flex-wrap: wrap;
}

.search-form input {
  padding: 0.75rem;
  border-radius: 6px;
  border: 1px solid #444;
  background-color: #242424;
  color: white;
  font-size: 1em;
  flex-grow: 1;
}

.search-form button {
  padding: 0.75rem 1.5rem;
  border: none;
  border-radius: 6px;
  background-color: #5f27cd;
  color: white;
  font-weight: bold;
  cursor: pointer;
}

.search-form button:disabled {
  background-color: #333;
  cursor: not-allowed;
}

.search-results-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
  gap: 1rem;
}

.clip-card {
  background-color: #242424;
  border-radius: 8px;
  overflow: hidden;
  position: relative;
}

.clip-card video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.clip-info {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  background: linear-gradient(to top, rgba(0,0,0,0.8), transparent);
  padding: 0.5rem;
  color: white;
  display: flex;
  justify-content: space-between;
  align-items: center;
}
.clip-title {
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    margin-right: 1rem;
}

--------

#.\services\video_scanner.py

# services/video_scanner.py

import os
from typing import Dict, List, Any

class VideoScanner:
    """
    Responsável por escanear um diretório em busca de arquivos de vídeo
    organizados em subpastas.
    """
    VIDEO_EXTENSIONS = ['.mp4', '.mkv', '.avi', '.mov', '.wmv', '.flv']

    def __init__(self, root_path: str):
        if not os.path.isdir(root_path):
            raise FileNotFoundError(f"O diretório raiz especificado não existe: {root_path}")
        self.root_path = root_path

    def scan(self) -> Dict[str, List[Dict[str, str]]]:
        """
        Executa o escaneamento e retorna um dicionário com os dados dos vídeos.
        Formato: {'Nome da Atriz': [{'name': 'Nome do Video', 'path': 'caminho/completo'}]}
        """
        video_data = {}
        
        try:
            # Lista as pastas (atrizes) dentro do diretório raiz
            actress_folders = [d for d in os.listdir(self.root_path) if os.path.isdir(os.path.join(self.root_path, d))]

            for actress in sorted(actress_folders): # Ordena para consistência
                actress_path = os.path.join(self.root_path, actress)
                videos = []
                
                # Lista os arquivos dentro da pasta da atriz
                for filename in sorted(os.listdir(actress_path)):
                    if any(filename.lower().endswith(ext) for ext in self.VIDEO_EXTENSIONS):
                        video_info = {
                            "name": os.path.splitext(filename)[0],
                            "path": os.path.join(actress_path, filename)
                        }
                        videos.append(video_info)
                
                if videos:
                    video_data[actress] = videos
                    
        except Exception as e:
            print(f"Ocorreu um erro ao escanear a pasta: {e}")
            return {} # Retorna um objeto vazio em caso de erro

        return video_data

--------

